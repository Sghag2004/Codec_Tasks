# -*- coding: utf-8 -*-
"""spam_email_classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FGY4PIYGtg4ZDKVi8eM1s5CJwcu3W9yk

## Load the dataset

### Subtask:
Load the 'spam_email.csv' dataset into a pandas DataFrame.

**Reasoning**:
Import pandas and load the dataset into a DataFrame.
"""

import pandas as pd

df = pd.read_csv('spam_email.csv')
df.head()

"""## Explore the data

### Subtask:
Display the first few rows of the dataset and check for missing values and data types.

**Reasoning**:
Display the first few rows of the DataFrame, check for missing values, and display data types as instructed.
"""

display(df.head())
display(df.isnull().sum())
df.info()

"""## Preprocess the text data

### Subtask:
Clean the email content by removing punctuation, converting to lowercase, and removing stop words. Convert the text data into numerical features using techniques like TF-IDF or Bag-of-Words.

**Reasoning**:
Import necessary libraries for text preprocessing and define a function to clean the text data, applying it to the DataFrame.
"""

import re
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer

# Download stopwords if not already downloaded
try:
    stopwords.words('english')
except LookupError:
    nltk.download('stopwords')

stop_words = set(stopwords.words('english'))

def clean_text(text):
    # Convert to lowercase
    text = text.lower()
    # Remove punctuation
    text = re.sub(r'[^\w\s]', '', text)
    # Remove stop words
    text = ' '.join([word for word in text.split() if word not in stop_words])
    return text

df['cleaned_text'] = df['text'].apply(clean_text)
display(df.head())

"""**Reasoning**:
Instantiate a TfidfVectorizer object and fit and transform the cleaned text data to convert it into numerical features.


"""

tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Limiting features to 5000 for manageability
X = tfidf_vectorizer.fit_transform(df['cleaned_text'])
print("Shape of the TF-IDF feature matrix:", X.shape)

"""## Split the dataset

### Subtask:
Split the dataset into training and testing sets.

**Reasoning**:
Split the feature matrix X and the target variable y into training and testing sets.
"""

from sklearn.model_selection import train_test_split

y = df['spam']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

"""## Train a classification model

### Subtask:
Train a Naive Bayes or Support Vector Machine (SVM) model on the training data.

**Reasoning**:
Import the Multinomial Naive Bayes model, instantiate it, and train it using the training data.
"""

from sklearn.naive_bayes import MultinomialNB

# Instantiate the Multinomial Naive Bayes model
model = MultinomialNB()

# Train the model using the training data
model.fit(X_train, y_train)

"""## Evaluate the model

### Subtask:
Evaluate the performance of the trained model on the testing data using metrics like accuracy, precision, recall, and F1-score.

**Reasoning**:
Evaluate the performance of the trained model using accuracy, precision, recall, and F1-score and print the results.
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Make predictions on the test data
y_pred = model.predict(X_test)

# Calculate the evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Print the results
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-score: {f1:.4f}")

"""## Summary:

### Data Analysis Key Findings

*   The dataset contains 5728 email entries with 'text' and 'spam' columns and no missing values.
*   The text data was preprocessed by converting to lowercase, removing punctuation, and removing stop words.
*   The cleaned text was converted into numerical features using TF-IDF vectorization, resulting in a feature matrix of shape (5728, 5000).
*   The dataset was split into training (80%) and testing (20%) sets, with shapes (4582, 5000) for training features and (1146, 5000) for testing features.
*   A Multinomial Naive Bayes model was trained on the training data.
*   The trained model achieved the following performance metrics on the testing data:
    *   Accuracy: 0.9782
    *   Precision: 0.9818
    *   Recall: 0.9310
    *   F1-score: 0.9558

### Insights or Next Steps

*   The trained Multinomial Naive Bayes model demonstrates high performance in identifying spam emails based on the evaluation metrics.

"""